{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "otherwise-watson",
   "metadata": {},
   "source": [
    "# ğŸ‘€ DAY 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-tokyo",
   "metadata": {},
   "source": [
    "- ~~`train`ì— ìˆëŠ” ë°ì´í„° ëª¨ë‘ í™•ì¥ì `.jpg`ë¡œ í†µì¼í•˜ê¸°~~\n",
    "- ~~evalì— ìˆëŠ” ë°ì´í„°ì™€ ê°™ì€ í˜•íƒœë¡œ `(ì´ë¯¸ì§€id, ì„±ë³„, ë‚˜ì´, í´ë˜ìŠ¤)`ë¡œ ë°ì´í„°ì…‹ êµ¬ì„±í•˜ì—¬ `train_modified.csv`ì— ì €ì¥í•˜ê¸°~~\n",
    "- ~~Datasetê³¼ DataLoaderë¡œ ìµœì¢… ë°ì´í„°ì…‹ êµ¬ì¶•í•˜ê¸°~~\n",
    "- ~~Pretrained ResNet ëª¨ë¸ë¡œ í™•ì¸í•˜ê¸°~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-hypothetical",
   "metadata": {},
   "source": [
    "## Imports and Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "opening-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version: 1.6.0\n",
      "This notebook use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from glob import glob\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# data processing\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms, models, utils\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "print(f'Pytorch version: {torch.__version__}')\n",
    "\n",
    "# device setting\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'This notebook use {device}')\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "square-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì¼ ê²½ë¡œ ì‚¬ìš©ì ì •ì˜\n",
    "class path:\n",
    "    train = '../input/data/train'\n",
    "    train_img = f'{train}/images'\n",
    "    train_df = f'{train}/train.csv'\n",
    "    test = '../input/data/eval'\n",
    "    test_img = f'{test}/images'\n",
    "    test_df = f'{test}/info.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-hydrogen",
   "metadata": {},
   "source": [
    "## TODO 1: Unify file extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-scientist",
   "metadata": {},
   "source": [
    "- ì´ë¯¸ì§€ í´ë”ì— ìˆëŠ” ëª¨ë“  í™•ì¥ìëª… ë½‘ì•„ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cubic-invitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'jpg': 18035, 'jpeg': 354, 'png': 511})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = glob(f'{path.train_img}/*')\n",
    "file_exts = []\n",
    "for folder_name in folders:\n",
    "    files = glob(f'{folder_name}/*')\n",
    "    for file_name in files:\n",
    "        ext = file_name.split('.')[-1].lower()\n",
    "        file_exts.append(ext)\n",
    "Counter(file_exts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-sending",
   "metadata": {},
   "source": [
    "> ëŒ€ë¶€ë¶„ì˜ íŒŒì¼ì´ `.jpg`ì¸ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ì•½ 900ê°œ ì •ë„ê°€ ë‹¤ë¥¸ í™•ì¥ëª…ì¸ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¬ ë•Œ í° ì´ìƒì€ ì—†ìœ¼ë¯€ë¡œ ë³€ê²½í•˜ì§€ ì•Šê¸°ë¡œ ê²°ì •!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-musician",
   "metadata": {},
   "source": [
    "## TODO 2: Create train_modified.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-buyer",
   "metadata": {},
   "source": [
    "- í”¼ì²˜ì˜ ì¡°í•©ë³„ í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "interracial-multimedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('wear', 'male', 0): 0,\n",
       " ('wear', 'male', 1): 1,\n",
       " ('wear', 'male', 2): 2,\n",
       " ('wear', 'female', 0): 3,\n",
       " ('wear', 'female', 1): 4,\n",
       " ('wear', 'female', 2): 5,\n",
       " ('incorrect', 'male', 0): 6,\n",
       " ('incorrect', 'male', 1): 7,\n",
       " ('incorrect', 'male', 2): 8,\n",
       " ('incorrect', 'female', 0): 9,\n",
       " ('incorrect', 'female', 1): 10,\n",
       " ('incorrect', 'female', 2): 11,\n",
       " ('not wear', 'male', 0): 12,\n",
       " ('not wear', 'male', 1): 13,\n",
       " ('not wear', 'male', 2): 14,\n",
       " ('not wear', 'female', 0): 15,\n",
       " ('not wear', 'female', 1): 16,\n",
       " ('not wear', 'female', 2): 17}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "mask = ['wear', 'incorrect', 'not wear']\n",
    "gender = ['male', 'female']\n",
    "age_bin = [0, 1, 2]\n",
    "\n",
    "combs = list(product(mask, gender, age_bin))\n",
    "num2class = {idx: value for idx, value in enumerate(combs)}\n",
    "class2num = {value: idx for idx, value in enumerate(combs)}\n",
    "class2num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-leone",
   "metadata": {},
   "source": [
    "- íŒŒì¼ëª…ì„ ê°€ì§€ê³  ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "asian-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_value(x):\n",
    "    if x == 'incorrect_mask':\n",
    "        return 'incorrect'\n",
    "    elif x == 'normal':\n",
    "        return 'not wear'\n",
    "    else:\n",
    "        return 'wear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sized-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = {'age': [], 'gender': [], 'mask': [], 'path': []}\n",
    "\n",
    "for folder_name in folders:\n",
    "    elem = folder_name.split('/')[-1].split('_')\n",
    "    gender, age = elem[1], int(elem[-1]) \n",
    "    files = glob(f'{folder_name}/*')\n",
    "    for file_path in files:\n",
    "        file_name = file_path.split('/')[-1].split('.')[0]\n",
    "        info_dict['age'].append(age)\n",
    "        info_dict['gender'].append(gender)\n",
    "        info_dict['mask'].append(get_mask_value(file_name))\n",
    "        info_dict['path'].append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "indian-batch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>mask</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>wear</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>not wear</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>wear</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>wear</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender       mask                                               path\n",
       "0   51  female       wear  ../input/data/train/images/000523_female_Asian...\n",
       "1   51  female   not wear  ../input/data/train/images/000523_female_Asian...\n",
       "2   51  female       wear  ../input/data/train/images/000523_female_Asian...\n",
       "3   51  female       wear  ../input/data/train/images/000523_female_Asian...\n",
       "4   51  female  incorrect  ../input/data/train/images/000523_female_Asian..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(info_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-assurance",
   "metadata": {},
   "source": [
    "- `age_bin` í”¼ì²˜ ìƒì„±: \"30ëŒ€ ë¯¸ë§Œ\"=0, \"30ëŒ€ ì´ìƒ, 60ëŒ€ ë¯¸ë§Œ\"=1, \"60ëŒ€ ì´ìƒ\"=2ë¡œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "identified-expert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>mask</th>\n",
       "      <th>path</th>\n",
       "      <th>age_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>wear</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>not wear</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>wear</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>wear</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender       mask                                               path  \\\n",
       "0   51  female       wear  ../input/data/train/images/000523_female_Asian...   \n",
       "1   51  female   not wear  ../input/data/train/images/000523_female_Asian...   \n",
       "2   51  female       wear  ../input/data/train/images/000523_female_Asian...   \n",
       "3   51  female       wear  ../input/data/train/images/000523_female_Asian...   \n",
       "4   51  female  incorrect  ../input/data/train/images/000523_female_Asian...   \n",
       "\n",
       "   age_bin  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_age_bin(x): \n",
    "    if x <30:\n",
    "        return 0\n",
    "    elif x >=30 and x <60:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "df['age_bin'] = df.age.map(get_age_bin)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-invasion",
   "metadata": {},
   "source": [
    "- `gender`, `mask`, `age_bin`ì„ ê°€ì§€ê³  ê° ë°ì´í„°ë³„ ë¼ë²¨ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "statewide-paper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>mask</th>\n",
       "      <th>path</th>\n",
       "      <th>age_bin</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>wear</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>not wear</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>wear</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>wear</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>female</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>../input/data/train/images/000523_female_Asian...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender       mask                                               path  \\\n",
       "0   51  female       wear  ../input/data/train/images/000523_female_Asian...   \n",
       "1   51  female   not wear  ../input/data/train/images/000523_female_Asian...   \n",
       "2   51  female       wear  ../input/data/train/images/000523_female_Asian...   \n",
       "3   51  female       wear  ../input/data/train/images/000523_female_Asian...   \n",
       "4   51  female  incorrect  ../input/data/train/images/000523_female_Asian...   \n",
       "\n",
       "   age_bin  target  \n",
       "0        1       4  \n",
       "1        1      16  \n",
       "2        1       4  \n",
       "3        1       4  \n",
       "4        1      10  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'] = df.apply(lambda x: class2num[(x['mask'], x['gender'], x['age_bin'])], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-chain",
   "metadata": {},
   "source": [
    "- `train_modified.csv`ë¡œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "wired-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'{path.train}/train_modified.csv', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-watts",
   "metadata": {},
   "source": [
    "## TODO 3: Create dataset for model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-petroleum",
   "metadata": {},
   "source": [
    "- custom dataset ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "informative-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        current_data = self.data.iloc[idx]\n",
    "        target = current_data.target\n",
    "        img = Image.open(current_data.path)\n",
    "        img = np.asarray(img)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, target\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "mineral-sewing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 18900\n",
      "Shape of image : (512, 384, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset = MaskDataset(f'{path.train}/train_modified.csv')\n",
    "print('Size of dataset :', len(dataset))\n",
    "print('Shape of image :', dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-frederick",
   "metadata": {},
   "source": [
    "- pklíŒŒì¼ë¡œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ethical-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path.train}/train_dataset.pkl', \"wb\") as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-pottery",
   "metadata": {},
   "source": [
    "- trainê³¼ validation setìœ¼ë¡œ ë¶„ë¦¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "expensive-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset)*0.8)\n",
    "valid_size = len(dataset) - train_size\n",
    "train, valid = random_split(dataset, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-seattle",
   "metadata": {},
   "source": [
    "## TODO 4: Train with pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-genre",
   "metadata": {},
   "source": [
    "- í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "recovered-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 14\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_WORKERS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-layer",
   "metadata": {},
   "source": [
    "- ë°ì´í„°ë¡œë” ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "resident-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "valid_loader = DataLoader(valid, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-conjunction",
   "metadata": {},
   "source": [
    "- pretrained resnet ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "jewish-copying",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True, progress=False)\n",
    "num_features = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_features, 18)\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "sunrise-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-flesh",
   "metadata": {},
   "source": [
    "- resnetìœ¼ë¡œ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "special-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(model, data_iter, batch_size):\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        model.eval()\n",
    "        for batch_img, batch_lab in data_iter:\n",
    "            X = batch_img.view(-1, 3, 384, 512).float().to(device)\n",
    "            Y = batch_lab.to(device)\n",
    "            y_pred = model(X)\n",
    "            _, predicted = torch.max(y_pred.data, 1)\n",
    "            correct += (predicted == Y).sum().item()\n",
    "            total += batch_img.size(0)\n",
    "        val_acc = (100 * correct / total)\n",
    "        model.train()\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "wicked-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train, test, model, criterion, optimizer, print_every=1):\n",
    "    print(f\"====== Training Starts! ======\")\n",
    "    for epoch in range(epochs):\n",
    "        loss_val_sum = 0\n",
    "        for batch_img, batch_lab in tqdm(train):\n",
    "            X = batch_img.view(-1, 3, 384, 512).float().to(device)\n",
    "            Y = batch_lab.to(device)\n",
    "\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, Y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "          \n",
    "            loss_val_sum += loss\n",
    "          \n",
    "        if ((epoch%print_every)==0) or (epoch==(epochs-1)):\n",
    "            loss_val_avg = loss_val_sum / len(train)\n",
    "            accr_val = test_eval(model, test, BATCH_SIZE)\n",
    "            print(f\"epoch:[{epoch+1}/{EPOCHS}] cost:[{loss_val_avg:.3f}] test_accuracy:[{accr_val:.3f}]\") \n",
    "\n",
    "    print(f\"====== Training Done! ======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "incorporated-messenger",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Training Starts! ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1080/1080 [06:21<00:00,  2.83it/s]\n",
      "  0%|          | 0/1080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[1/5] cost:[1.848] test_accuracy:[55.926]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1080/1080 [06:21<00:00,  2.83it/s]\n",
      "  0%|          | 0/1080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[2/5] cost:[1.293] test_accuracy:[66.217]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1080/1080 [06:21<00:00,  2.83it/s]\n",
      "  0%|          | 0/1080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[3/5] cost:[0.988] test_accuracy:[73.704]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1080/1080 [06:20<00:00,  2.84it/s]\n",
      "  0%|          | 0/1080 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[4/5] cost:[0.746] test_accuracy:[77.354]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1080/1080 [06:21<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[5/5] cost:[0.581] test_accuracy:[79.127]\n",
      "====== Training Done! ======\n"
     ]
    }
   ],
   "source": [
    "train_model(train_loader, valid_loader, resnet, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-comparison",
   "metadata": {},
   "source": [
    "- evalì „ìš© Dataset ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "orange-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "        image = np.asarray(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "awful-trout",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12600/12600 [02:58<00:00, 70.78it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-afd0d5fa678a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# ì œì¶œí•  íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'submission_202103311709.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test inference is done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# meta ë°ì´í„°ì™€ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "submission = pd.read_csv(os.path.join(path.test, 'info.csv'))\n",
    "image_dir = os.path.join(path.test, 'images')\n",
    "\n",
    "# Test Dataset í´ë˜ìŠ¤ ê°ì²´ë¥¼ ìƒì„±í•˜ê³  DataLoaderë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "dataset = TestDataset(image_paths)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤. (í•™ìŠµí•œ ëª¨ë¸ì´ ìˆë‹¤ë©´ torch.loadë¡œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì£¼ì„¸ìš”!)\n",
    "resnet.eval()\n",
    "\n",
    "# ëª¨ë¸ì´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ì˜ˆì¸¡í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "all_predictions = []\n",
    "for images in tqdm(loader):\n",
    "    with torch.no_grad():\n",
    "        images = images.view(-1, 3, 384, 512).float().to(device)\n",
    "        pred = resnet(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "incorporate-manual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "# ì œì¶œí•  íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "submission.to_csv(os.path.join(path.test, 'submission_202103311709.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
